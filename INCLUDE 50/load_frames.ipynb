{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/pose_landmarker_heavy.task'\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "options_pose = PoseLandmarkerOptions(base_options = BaseOptions(model_asset_path = model_path),running_mode=VisionRunningMode.IMAGE)\n",
    "MARGIN = 10 \n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "\n",
    "options_hand = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=\"C:\\Projects\\ISL-to-text\\INCLUDE 50\\MP_Models\\hand_landmarker.task\"),\n",
    "    running_mode=VisionRunningMode.IMAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_pose(img, result):\n",
    "    if len(result.pose_landmarks)>0:\n",
    "        landmarks = result.pose_landmarks[0]\n",
    "        image = np.copy(img)\n",
    "        x = []\n",
    "        y = []\n",
    "        for landmark in landmarks:\n",
    "            x.append(landmark.x)\n",
    "            y.append(landmark.y)\n",
    "        lm_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        lm_proto.landmark.extend([landmark_pb2.NormalizedLandmark(x= landmark.x,y= landmark.y, z=landmark.z) for landmark in landmarks])\n",
    "        solutions.drawing_utils.draw_landmarks(image,lm_proto)\n",
    "        return image,x,y\n",
    "    else:\n",
    "        return img,[],[]\n",
    "    \n",
    "def draw_landmarks_hand(rgb_image, detection_result):\n",
    "    hand_landmarks_list = detection_result.hand_landmarks\n",
    "    handedness_list = detection_result.handedness\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "    x_coordinates = []\n",
    "    y_coordinates = []\n",
    "    for idx in range(len(hand_landmarks_list)):\n",
    "        hand_landmarks = hand_landmarks_list[idx]\n",
    "        handedness = handedness_list[idx]\n",
    "\n",
    "        hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        hand_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "            ])\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_image,\n",
    "            hand_landmarks_proto,\n",
    "            solutions.hands.HAND_CONNECTIONS,\n",
    "            solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "            solutions.drawing_styles.get_default_hand_connections_style())\n",
    "    \n",
    "        height, width, _ = annotated_image.shape\n",
    "        x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "        y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "        text_x = int(min(x_coordinates) * width)\n",
    "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "        cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    return annotated_image,x_coordinates,y_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[landmark {\n",
      "  x: 0.395729482\n",
      "  y: 0.388442218\n",
      "  z: 1.377731e-007\n",
      "}\n",
      "landmark {\n",
      "  x: 0.405753523\n",
      "  y: 0.378838062\n",
      "  z: -0.00759254768\n",
      "}\n",
      "landmark {\n",
      "  x: 0.412032545\n",
      "  y: 0.357417673\n",
      "  z: -0.0110371886\n",
      "}\n",
      "landmark {\n",
      "  x: 0.415762752\n",
      "  y: 0.340862662\n",
      "  z: -0.0128710978\n",
      "}\n",
      "landmark {\n",
      "  x: 0.419211686\n",
      "  y: 0.326015621\n",
      "  z: -0.014600995\n",
      "}\n",
      "landmark {\n",
      "  x: 0.401755691\n",
      "  y: 0.337082148\n",
      "  z: -0.00983852707\n",
      "}\n",
      "landmark {\n",
      "  x: 0.409330964\n",
      "  y: 0.3151564\n",
      "  z: -0.0148387887\n",
      "}\n",
      "landmark {\n",
      "  x: 0.415798038\n",
      "  y: 0.300329804\n",
      "  z: -0.0188644882\n",
      "}\n",
      "landmark {\n",
      "  x: 0.420998096\n",
      "  y: 0.290228903\n",
      "  z: -0.0212903954\n",
      "}\n",
      "landmark {\n",
      "  x: 0.397450387\n",
      "  y: 0.336183131\n",
      "  z: -0.00707287062\n",
      "}\n",
      "landmark {\n",
      "  x: 0.405655265\n",
      "  y: 0.314469606\n",
      "  z: -0.0114022885\n",
      "}\n",
      "landmark {\n",
      "  x: 0.412553251\n",
      "  y: 0.301673263\n",
      "  z: -0.0142195495\n",
      "}\n",
      "landmark {\n",
      "  x: 0.418042332\n",
      "  y: 0.2919797\n",
      "  z: -0.0160362143\n",
      "}\n",
      "landmark {\n",
      "  x: 0.395074576\n",
      "  y: 0.336248487\n",
      "  z: -0.00479251752\n",
      "}\n",
      "landmark {\n",
      "  x: 0.403080761\n",
      "  y: 0.315873772\n",
      "  z: -0.00813056901\n",
      "}\n",
      "landmark {\n",
      "  x: 0.409695148\n",
      "  y: 0.30409956\n",
      "  z: -0.00932153128\n",
      "}\n",
      "landmark {\n",
      "  x: 0.415179193\n",
      "  y: 0.294685602\n",
      "  z: -0.00996981282\n",
      "}\n",
      "landmark {\n",
      "  x: 0.393753618\n",
      "  y: 0.337997377\n",
      "  z: -0.00310165668\n",
      "}\n",
      "landmark {\n",
      "  x: 0.399818897\n",
      "  y: 0.319961\n",
      "  z: -0.00553853717\n",
      "}\n",
      "landmark {\n",
      "  x: 0.405492395\n",
      "  y: 0.310152322\n",
      "  z: -0.00605879398\n",
      "}\n",
      "landmark {\n",
      "  x: 0.41058138\n",
      "  y: 0.303664\n",
      "  z: -0.00614551874\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(\"C:\\Projects\\ISL Research\\INCLUDE50\\Places_1of4\\Places/19. House\\MVI_3350.MOV\")\n",
    "\n",
    "while vid.isOpened():\n",
    "    suc,frame = vid.read()\n",
    "    while suc:\n",
    "        cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/frame.png',frame)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "        h,w,_  = frame.shape\n",
    "        with PoseLandmarker.create_from_options(options_pose) as landmarker:\n",
    "            results = landmarker.detect(mp_image)\n",
    "        frame,_,_ = draw_landmarks_pose(frame,results)\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks[0]\n",
    "            min_x = min([(landmark.x)*w for landmark in landmarks]) -130\n",
    "            max_x = max([(landmark.x)*w for landmark in landmarks]) +130\n",
    "            min_y = min([(landmark.y)*h for landmark in landmarks]) -130\n",
    "            max_y = max([(landmark.y)*h for landmark in landmarks])  +130\n",
    "        img = frame[int(min_y):int(max_y),int(min_x):int(max_x)]\n",
    "        cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/crop.png',img)\n",
    "        image = mp.Image(image_format=mp.ImageFormat.SRGB, data=np.array(img))\n",
    "        with HandLandmarker.create_from_options(options_hand) as landmarker:\n",
    "            landmarks = landmarker.detect(image)\n",
    "        an_img,x,y = draw_landmarks_hand(img,landmarks)\n",
    "        print(landmarks)\n",
    "        cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/annotatedframe.png',an_img)\n",
    "        suc,frame = vid.read()\n",
    "    vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HandLandmarkerResult(handedness=[], hand_landmarks=[], hand_world_landmarks=[])\n"
     ]
    }
   ],
   "source": [
    "print(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format for getting coordinates from landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "landmarks.pose_landmarks[0][index].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.534977  0.551095  0.559139  0.564903  0.526483  0.518967  0.510994   \n",
      "\n",
      "        7         8         9    ...       141       142       143       144  \\\n",
      "0  0.579321  0.505561  0.554191  ...  0.074779  0.157729  0.117867  0.091306   \n",
      "\n",
      "       145       146       147       148       149    150  \n",
      "0  0.07216  0.164582  0.135074  0.113023  0.094968  angry  \n",
      "\n",
      "[1 rows x 151 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.499329  0.511712  0.520211  0.527218  0.488838  0.481872  0.474852   \n",
      "\n",
      "        7         8         9    ... 141 142 143 144 145 146 147 148 149  \\\n",
      "0  0.538835  0.468964  0.517445  ...   0   0   0   0   0   0   0   0   0   \n",
      "\n",
      "     150  \n",
      "0  angry  \n",
      "\n",
      "[1 rows x 151 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.536189  0.551367  0.558678  0.564701  0.525808  0.518358  0.510009   \n",
      "\n",
      "        7         8         9    ...       141       142       143      144  \\\n",
      "0  0.578015  0.502063  0.553199  ...  0.129889  0.167938  0.123677  0.11791   \n",
      "\n",
      "        145       146       147       148       149    150  \n",
      "0  0.130466  0.165874  0.129703  0.125295  0.137225  angry  \n",
      "\n",
      "[1 rows x 151 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "#Load Frames form still image folder\n",
    "path = 'C:\\Projects\\ISL-to-text\\Word Level ISL' # path to root foldere\n",
    "# start loop with word as listdir through entire staationary image folder\n",
    "word = 'angry'\n",
    "data = pd.DataFrame()\n",
    "for file in os.listdir(path): # update listdir with word\n",
    "    dt = []\n",
    "    frame = cv2.imread(os.path.join(path,file)) # here too\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "    h,w,_  = frame.shape\n",
    "    with PoseLandmarker.create_from_options(options_pose) as landmarker:\n",
    "        results = landmarker.detect(mp_image)\n",
    "    frame,_,_ = draw_landmarks_pose(frame,results)\n",
    "    if(len(results.pose_landmarks)!=0):\n",
    "        X_pose = [results.pose_landmarks[0][i].x for i in range(len(results.pose_landmarks[0]))]\n",
    "        Y_pose = [results.pose_landmarks[0][i].y for i in range(len(results.pose_landmarks[0]))]\n",
    "        landmarks = results.pose_landmarks[0]\n",
    "        min_x = min(X_pose)*w -130\n",
    "        max_x = max(X_pose)*w +130\n",
    "        min_y = min(Y_pose)*h -130\n",
    "        max_y = max(Y_pose)*h +130\n",
    "        img = frame[int(min_y):int(max_y),int(min_x):int(max_x)]\n",
    "        cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/crop.png',img)\n",
    "        image = mp.Image(image_format=mp.ImageFormat.SRGB, data=np.array(img))\n",
    "        with HandLandmarker.create_from_options(options_hand) as landmarker:\n",
    "            landmarks = landmarker.detect(image)\n",
    "        an_img,x,y = draw_landmarks_hand(img,landmarks)\n",
    "        if(len(landmarks.hand_landmarks)!=0):\n",
    "            X_left = [0 for i in range(21)]\n",
    "            X_right = [0 for i in range(21)]\n",
    "            Y_left = [0 for i in range(21)]\n",
    "            Y_right = [0 for i in range(21)]\n",
    "            for j in range(len(landmarks.hand_landmarks)):\n",
    "                if landmarks.handedness[j][0].display_name == 'Right':\n",
    "                    X_right = [landmarks.hand_landmarks[j][i].x for i in range(len(landmarks.hand_landmarks[j]))]\n",
    "                    Y_right = [landmarks.hand_landmarks[j][i].y for i in range(len(landmarks.hand_landmarks[j]))]\n",
    "                if landmarks.handedness[j][0].display_name == 'Left':\n",
    "                    X_left = [landmarks.hand_landmarks[j][i].x for i in range(len(landmarks.hand_landmarks[j]))]\n",
    "                    Y_left = [landmarks.hand_landmarks[j][i].y for i in range(len(landmarks.hand_landmarks[j]))]\n",
    "            dt = [*X_pose,*Y_pose,*X_left,*Y_left,*X_right,*Y_right,word]\n",
    "            print(pd.DataFrame(dt).T)\n",
    "            data = pd.concat([data,pd.DataFrame(dt).T])\n",
    "            cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/lmed'+file+'.png',an_img)\n",
    "data.to_csv('C:\\Projects\\ISL-to-text\\INCLUDE 50\\Word level data/'+word+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right\n"
     ]
    }
   ],
   "source": [
    "print(landmarks.handedness[0][0].display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unable to open file at c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages/C:\\Projects\\ISL-to-text\\INCLUDE 50\\MP_Models\\hand_landmarker.task, errno=22",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mImage(image_format\u001b[38;5;241m=\u001b[39mmp\u001b[38;5;241m.\u001b[39mImageFormat\u001b[38;5;241m.\u001b[39mSRGB, data\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mProjects\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mISL-to-text\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mWord Level ISL\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mopen-hand-on-white-background-260nw-407475856.webp\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mHandLandmarker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_from_options\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptions_hand\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m landmarker:\n\u001b[0;32m      3\u001b[0m        landmarks \u001b[38;5;241m=\u001b[39m landmarker\u001b[38;5;241m.\u001b[39mdetect(image)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(landmarks\u001b[38;5;241m.\u001b[39mhandedness)\n",
      "File \u001b[1;32mc:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\tasks\\python\\vision\\hand_landmarker.py:364\u001b[0m, in \u001b[0;36mHandLandmarker.create_from_options\u001b[1;34m(cls, options)\u001b[0m\n\u001b[0;32m    342\u001b[0m   options\u001b[38;5;241m.\u001b[39mresult_callback(\n\u001b[0;32m    343\u001b[0m       hand_landmarks_detection_result,\n\u001b[0;32m    344\u001b[0m       image,\n\u001b[0;32m    345\u001b[0m       timestamp\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m _MICRO_SECONDS_PER_MILLISECOND,\n\u001b[0;32m    346\u001b[0m   )\n\u001b[0;32m    348\u001b[0m task_info \u001b[38;5;241m=\u001b[39m _TaskInfo(\n\u001b[0;32m    349\u001b[0m     task_graph\u001b[38;5;241m=\u001b[39m_TASK_GRAPH_NAME,\n\u001b[0;32m    350\u001b[0m     input_streams\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    362\u001b[0m     task_options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    363\u001b[0m )\n\u001b[1;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask_info\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_graph_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_flow_limiting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mode\u001b[49m\n\u001b[0;32m    367\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_RunningMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLIVE_STREAM\u001b[49m\n\u001b[0;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpackets_callback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult_callback\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\mediapipe\\tasks\\python\\vision\\core\\base_vision_task_api.py:70\u001b[0m, in \u001b[0;36mBaseVisionTaskApi.__init__\u001b[1;34m(self, graph_config, running_mode, packet_callback)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m packet_callback:\n\u001b[0;32m     66\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe vision task is in image or video mode, a user-defined result \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     68\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcallback should not be provided.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     69\u001b[0m   )\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_runner \u001b[38;5;241m=\u001b[39m \u001b[43m_TaskRunner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacket_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_running_mode \u001b[38;5;241m=\u001b[39m running_mode\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to open file at c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages/C:\\Projects\\ISL-to-text\\INCLUDE 50\\MP_Models\\hand_landmarker.task, errno=22"
     ]
    }
   ],
   "source": [
    "image = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.imread('C:\\Projects\\ISL-to-text\\Word Level ISL\\open-hand-on-white-background-260nw-407475856.webp'))\n",
    "with HandLandmarker.create_from_options(options_hand) as landmarker:\n",
    "       landmarks = landmarker.detect(image)\n",
    "print(landmarks.handedness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for which hand, pair with check for how many hands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "1. If one of the hands is undetected/random, that hand can take any position, use to augment data, use atleast 20 random undetected hand positions to crfeate 20x new entries.\n",
    "2. Match the number and side of hands detected in each category and eleminate the odd ones.\n",
    "3. Augment the data based on the open and closed palm simulation.\n",
    "4. augment the data using spacial transformations like the venus paper.\n",
    "5. fred data into embedding layer (returns 3 vectors of 42,1)\n",
    "6. Throw into a Transformer Encoder without the positional engoding.\n",
    "7. Use a transformer decoder with avalible dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGRY\n"
     ]
    }
   ],
   "source": [
    "print(file[:-8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

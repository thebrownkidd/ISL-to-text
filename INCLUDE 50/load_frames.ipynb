{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/pose_landmarker_heavy.task'\n",
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "options_pose = PoseLandmarkerOptions(base_options = BaseOptions(model_asset_path = model_path),running_mode=VisionRunningMode.IMAGE)\n",
    "MARGIN = 10 \n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'HandLandmarkerOptions' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m HandLandmarker \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvision\u001b[38;5;241m.\u001b[39mHandLandmarker\n\u001b[0;32m      2\u001b[0m HandLandmarkerOptions \u001b[38;5;241m=\u001b[39m mp\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvision\u001b[38;5;241m.\u001b[39mHandLandmarkerOptions(BaseOptions)\n\u001b[1;32m----> 4\u001b[0m options_hand \u001b[38;5;241m=\u001b[39m \u001b[43mHandLandmarkerOptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBaseOptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_asset_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mProjects\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mISL-to-text\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mINCLUDE 50\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mMP_Models\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mhand_landmarker.task\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrunning_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVisionRunningMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGE\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'HandLandmarkerOptions' object is not callable"
     ]
    }
   ],
   "source": [
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "\n",
    "options_hand = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=\"C:\\Projects\\ISL-to-text\\INCLUDE 50\\MP_Models\\hand_landmarker.task\"),\n",
    "    running_mode=VisionRunningMode.IMAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_pose(img, result):\n",
    "    if len(result.pose_landmarks)>0:\n",
    "        landmarks = result.pose_landmarks[0]\n",
    "        image = np.copy(img)\n",
    "        x = []\n",
    "        y = []\n",
    "        for landmark in landmarks:\n",
    "            x.append(landmark.x)\n",
    "            y.append(landmark.y)\n",
    "        lm_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        lm_proto.landmark.extend([landmark_pb2.NormalizedLandmark(x= landmark.x,y= landmark.y, z=landmark.z) for landmark in landmarks])\n",
    "        solutions.drawing_utils.draw_landmarks(image,lm_proto)\n",
    "        return image,x,y\n",
    "    else:\n",
    "        return img,[],[]\n",
    "    \n",
    "def draw_landmarks_hand(rgb_image, detection_result):\n",
    "    hand_landmarks_list = detection_result.hand_landmarks\n",
    "    handedness_list = detection_result.handedness\n",
    "    annotated_image = np.copy(rgb_image)\n",
    "    x_coordinates = []\n",
    "    y_coordinates = []\n",
    "    for idx in range(len(hand_landmarks_list)):\n",
    "        hand_landmarks = hand_landmarks_list[idx]\n",
    "        handedness = handedness_list[idx]\n",
    "\n",
    "        hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        hand_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "            ])\n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_image,\n",
    "            hand_landmarks_proto,\n",
    "            solutions.hands.HAND_CONNECTIONS,\n",
    "            solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "            solutions.drawing_styles.get_default_hand_connections_style())\n",
    "    \n",
    "        height, width, _ = annotated_image.shape\n",
    "        x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "        y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "        text_x = int(min(x_coordinates) * width)\n",
    "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "        cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "    return annotated_image,x_coordinates,y_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "[landmark {\n",
      "  x: 0.395729482\n",
      "  y: 0.388442218\n",
      "  z: 1.377731e-007\n",
      "}\n",
      "landmark {\n",
      "  x: 0.405753523\n",
      "  y: 0.378838062\n",
      "  z: -0.00759254768\n",
      "}\n",
      "landmark {\n",
      "  x: 0.412032545\n",
      "  y: 0.357417673\n",
      "  z: -0.0110371886\n",
      "}\n",
      "landmark {\n",
      "  x: 0.415762752\n",
      "  y: 0.340862662\n",
      "  z: -0.0128710978\n",
      "}\n",
      "landmark {\n",
      "  x: 0.419211686\n",
      "  y: 0.326015621\n",
      "  z: -0.014600995\n",
      "}\n",
      "landmark {\n",
      "  x: 0.401755691\n",
      "  y: 0.337082148\n",
      "  z: -0.00983852707\n",
      "}\n",
      "landmark {\n",
      "  x: 0.409330964\n",
      "  y: 0.3151564\n",
      "  z: -0.0148387887\n",
      "}\n",
      "landmark {\n",
      "  x: 0.415798038\n",
      "  y: 0.300329804\n",
      "  z: -0.0188644882\n",
      "}\n",
      "landmark {\n",
      "  x: 0.420998096\n",
      "  y: 0.290228903\n",
      "  z: -0.0212903954\n",
      "}\n",
      "landmark {\n",
      "  x: 0.397450387\n",
      "  y: 0.336183131\n",
      "  z: -0.00707287062\n",
      "}\n",
      "landmark {\n",
      "  x: 0.405655265\n",
      "  y: 0.314469606\n",
      "  z: -0.0114022885\n",
      "}\n",
      "landmark {\n",
      "  x: 0.412553251\n",
      "  y: 0.301673263\n",
      "  z: -0.0142195495\n",
      "}\n",
      "landmark {\n",
      "  x: 0.418042332\n",
      "  y: 0.2919797\n",
      "  z: -0.0160362143\n",
      "}\n",
      "landmark {\n",
      "  x: 0.395074576\n",
      "  y: 0.336248487\n",
      "  z: -0.00479251752\n",
      "}\n",
      "landmark {\n",
      "  x: 0.403080761\n",
      "  y: 0.315873772\n",
      "  z: -0.00813056901\n",
      "}\n",
      "landmark {\n",
      "  x: 0.409695148\n",
      "  y: 0.30409956\n",
      "  z: -0.00932153128\n",
      "}\n",
      "landmark {\n",
      "  x: 0.415179193\n",
      "  y: 0.294685602\n",
      "  z: -0.00996981282\n",
      "}\n",
      "landmark {\n",
      "  x: 0.393753618\n",
      "  y: 0.337997377\n",
      "  z: -0.00310165668\n",
      "}\n",
      "landmark {\n",
      "  x: 0.399818897\n",
      "  y: 0.319961\n",
      "  z: -0.00553853717\n",
      "}\n",
      "landmark {\n",
      "  x: 0.405492395\n",
      "  y: 0.310152322\n",
      "  z: -0.00605879398\n",
      "}\n",
      "landmark {\n",
      "  x: 0.41058138\n",
      "  y: 0.303664\n",
      "  z: -0.00614551874\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arpit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "vid = cv2.VideoCapture(\"C:\\Projects\\ISL Research\\INCLUDE50\\Places_1of4\\Places/19. House\\MVI_3350.MOV\")\n",
    "\n",
    "while vid.isOpened():\n",
    "    suc,frame = vid.read()\n",
    "    while suc:\n",
    "        cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/frame.png',frame)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "        h,w,_  = frame.shape\n",
    "        with PoseLandmarker.create_from_options(options_pose) as landmarker:\n",
    "            results = landmarker.detect(mp_image)\n",
    "        frame,_,_ = draw_landmarks_pose(frame,results)\n",
    "        if results.pose_landmarks:\n",
    "            landmarks = results.pose_landmarks[0]\n",
    "            min_x = min([(landmark.x)*w for landmark in landmarks]) -130\n",
    "            max_x = max([(landmark.x)*w for landmark in landmarks]) +130\n",
    "            min_y = min([(landmark.y)*h for landmark in landmarks]) -130\n",
    "            max_y = max([(landmark.y)*h for landmark in landmarks])  +130\n",
    "        img = frame[int(min_y):int(max_y),int(min_x):int(max_x)]\n",
    "        cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/crop.png',img)\n",
    "        image = mp.Image(image_format=mp.ImageFormat.SRGB, data=np.array(img))\n",
    "        with HandLandmarker.create_from_options(options_hand) as landmarker:\n",
    "            landmarks = landmarker.detect(image)\n",
    "        an_img,x,y = draw_landmarks_hand(img,landmarks)\n",
    "        print(landmarks)\n",
    "        cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/annotatedframe.png',an_img)\n",
    "        suc,frame = vid.read()\n",
    "    vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HandLandmarkerResult(handedness=[], hand_landmarks=[], hand_world_landmarks=[])\n"
     ]
    }
   ],
   "source": [
    "print(landmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format for getting coordinates from landmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "landmarks.pose_landmarks[0][index].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5        6    \\\n",
      "0  0.321927  0.367557  0.398131  0.420993  0.433352  0.365919  0.38588   \n",
      "\n",
      "        7         8         9    ...       98        99        100       101  \\\n",
      "0  0.402396  0.414219  0.343575  ...  0.980694  0.964583  1.285955  1.262193   \n",
      "\n",
      "        102       103       104       105      106       107  \n",
      "0  1.549406  1.611993  1.586205  1.665215  1.65706  1.731151  \n",
      "\n",
      "[1 rows x 108 columns]\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.611738  0.563684  0.531936  0.519073  0.523354  0.530424  0.513039   \n",
      "\n",
      "        7         8         9    ...       98        99        100       101  \\\n",
      "0  0.503784  0.495838  0.557465  ...  0.831884  0.827637  1.128295  1.106931   \n",
      "\n",
      "        102       103       104       105      106       107  \n",
      "0  1.423614  1.419779  1.462954  1.467066  1.54403  1.528466  \n",
      "\n",
      "[1 rows x 108 columns]\n",
      "        0         1         2        3         4         5         6    \\\n",
      "0  0.310325  0.358346  0.392651  0.41941  0.435648  0.362793  0.383502   \n",
      "\n",
      "       7        8         9    ...       98        99        100       101  \\\n",
      "0  0.40512  0.42014  0.347276  ...  1.006092  0.991105  1.376977  1.347896   \n",
      "\n",
      "        102       103       104       105       106       107  \n",
      "0  1.667684  1.690797  1.709186  1.746663  1.778387  1.800765  \n",
      "\n",
      "[1 rows x 108 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load Frames form still image folder\n",
    "path = 'C:\\Projects\\ISL-to-text\\Word Level ISL' # path to root foldere\n",
    "# start loop with word as listdir through entire staationary image folder\n",
    "word = 'angry'\n",
    "data = pd.DataFrame()\n",
    "for file in os.listdir(path): # update listdir with word\n",
    "    dt = []\n",
    "    frame = cv2.imread(os.path.join(path,file)) # here too\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame)\n",
    "    h,w,_  = frame.shape\n",
    "    with PoseLandmarker.create_from_options(options_pose) as landmarker:\n",
    "        results = landmarker.detect(mp_image)\n",
    "    frame,_,_ = draw_landmarks_pose(frame,results)\n",
    "    if(len(results.pose_landmarks)!=0):\n",
    "        X_pose = [results.pose_landmarks[0][i].x for i in range(len(results.pose_landmarks[0]))]\n",
    "        Y_pose = [results.pose_landmarks[0][i].y for i in range(len(results.pose_landmarks[0]))]\n",
    "        landmarks = results.pose_landmarks[0]\n",
    "        min_x = min(X_pose)*w -130\n",
    "        max_x = max(X_pose)*w +130\n",
    "        min_y = min(Y_pose)*h -130\n",
    "        max_y = max(Y_pose)*h +130\n",
    "        img = frame[int(min_y):int(max_y),int(min_x):int(max_x)]\n",
    "        cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/crop.png',img)\n",
    "        image = mp.Image(image_format=mp.ImageFormat.SRGB, data=np.array(img))\n",
    "        with HandLandmarker.create_from_options(options_hand) as landmarker:\n",
    "            landmarks = landmarker.detect(image)\n",
    "        an_img,x,y = draw_landmarks_hand(img,landmarks)\n",
    "        if(len(landmarks.hand_landmarks)!=0):\n",
    "            X_left = [0 for i in range(21)]\n",
    "            X_right = [0 for i in range(21)]\n",
    "            Y_left = [0 for i in range(21)]\n",
    "            Y_right = [0 for i in range(21)]\n",
    "            for j in range(len(landmarks.hand_landmarks)):\n",
    "                if landmarks.handedness[j].\n",
    "                X_hand = [landmark[i].x for i in range(len(landmarks.hand_landmarks[0]))]\n",
    "                Y_hand = [landmark[i].y for i in range(len(landmarks.hand_landmarks[0]))]\n",
    "            dt = [*X_hand,*Y_hand,*X_pose,*Y_pose] #fix\n",
    "            print(pd.DataFrame(dt).T)\n",
    "            data = pd.concat([data,pd.DataFrame(dt).T])\n",
    "            cv2.imwrite('C:/Projects/ISL-to-text/INCLUDE 50/MP_Models/lmed'+file+'.png',an_img)\n",
    "data.to_csv('C:\\Projects\\ISL-to-text\\INCLUDE 50\\Word level data/'+word+'.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "image = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.imread('C:\\Projects\\ISL-to-text\\Word Level ISL\\open-hand-on-white-background-260nw-407475856.webp'))\n",
    "with HandLandmarker.create_from_options(options_hand) as landmarker:\n",
    "       landmarks = landmarker.detect(image)\n",
    "print(landmarks.handedness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for which hand, pair with check for how many hands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "1. If one of the hands is undetected/random, that hand can take any position, use to augment data, use atleast 20 random undetected hand positions to crfeate 20x new entries.\n",
    "2. Match the number and side of hands detected in each category and eleminate the odd ones.\n",
    "3. Augment the data based on the open and closed palm simulation.\n",
    "4. augment the data using spacial transformations like the venus paper.\n",
    "5. fred data into embedding layer (returns 3 vectors of 42,1)\n",
    "6. Throw into a Transformer Encoder without the positional engoding.\n",
    "7. Use a transformer decoder with avalible dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGRY\n"
     ]
    }
   ],
   "source": [
    "print(file[:-8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
